---
layout: post
title: MongoDB导入数据性能优化
updated: 2014-12-11 01:15
description: 需要通过Excel导入10W+的数据，我从之前的同事交接此工作。刚开始数据量比较小导入时间还能勉强接受，随着业务数据量的增大，导入时间已经增长到24个小时左右了
category: Database
tags: [MongoDB]
---

## 背景
公司的一个项目每个月都需要通过Excel导入10W+的数据，我从之前的同事交接此工作。刚开始数据量比较小导入时间还能勉强接受，随着业务数据量的增大，导入时间已经增长到24个小时左右了。最后自己实在受不了这个速度，决定优化代码。

<!--more-->

## 方案
### 评估代码的效率

使用1000测试数据导入得到导入数据时间，计算每条数据平均导入时间为

每条数据导入时间=导入时间/1000=0.7s

### 分析代码逻辑

代码逻辑分为了以下几个步骤

1.读取数据到内存
2.初始化校验规则
3.循环每条数据写入数据库

由于1和2步骤只执行一次，时间忽略不计。接着对3步骤进行分析。

3.1.截取数据
3.2.校验数据有效性
3.3.查询目前数据库中是否已经存在主键相同的数据（联合主键）
3.4.如果3查询存在则更新，不存在则插入

### 调试性能

在3的子步骤分别设置时间点，最后打印每个步骤所耗费的时间（个人认为应该有成熟的工具对代码性能进行分析，如果有人知道麻烦告诉我一声，^_^）。最后发现在3.3和3.4两个步骤所花费的时间占整体时间的90%左右，目标已经确定是IO产生的瓶颈。

### 优化代码

3.3和3.4的逻辑伪代码为如下所示。

	result = db.collection.find_one(xxxx)
	if result:
		update
	else:
		insert
这样的弊端就是需要与数据库进行两次交互，一次读，一次写。而MongoDB中引入了一种叫做upsert的特殊更新，如果没有文档符合更新条件，就会以这个条件和更新文档为基础创建一个新的文档；如果找到了匹配文档，则正常更新。

另外，调试的时候发现在70W+的数据中查询一条数据的时间约为0.3s，当时第一想法就是组合索引。果然建立完索引以后，查询速度缩减到0.03s左右。MongoDB操作索引的方式也很简单，点击MongoDB/bin/mongo.exe进行管理工具，下面举例对user建立索引。

	#建立单条件索引,1代表按照name进行升序，-1代表降序。
	db.user.ensureIndex({"name:1"})
	#建立联合索引
	db.user.ensureIndex({"name":1,"age":-1})
	#查询索引，可以看到user下面所有Index的具体信息
	db.user.getIndexes()
	#删除索引，这里的参数是index的name
	db.user.dropIndexes({"name_1"})

## 总结

框架带来写代码便利的同时，会造成性能一定程度的降低。
对于频繁查询字段应建立索引提高效率。当然索引带来弊端是需要额外的空间来存储索引，不过所占用的额外空间对于性能的提升来说不足一提。
